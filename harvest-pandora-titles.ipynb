{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6464b6f6-e5d9-45a6-92fb-0b6a7216040c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Harvest the full collection of Pandora titles\n",
    "\n",
    "This notebook harvests a complete collection of archived web page titles from [Pandora](http://pandora.nla.gov.au/), the National Library of Australia's selective web archive.\n",
    "\n",
    "Pandora has been selecting web sites and online resources for preservation since 1996. It has assembled a collection of more than 80,000 titles, organised into subjects and collections. The archived websites are now part of the Australian Web Archive (AWA), which combines the selected titles with broader domain harvests, and is searchable through Trove. However, Pandora's curated collections offer a useful entry point for researchers trying to find web sites relating to particular topics or events.\n",
    "\n",
    "By combining the list of titles with data [harvested from Pandora's hierarchy of subjects and collections](harvest-pandora-subject-collections.ipynb), you can [create datasets of archived urls relating to specific topics](create-datasets.ipynb).\n",
    "\n",
    "## What are titles?\n",
    "\n",
    "Pandora's 'titles' are not single resources, they're groups of resources. Titles link to snapshots of a web resource captured on different dates (also known as [Mementos](https://glam-workbench.net/web-archives/timegates-timemaps-mementos/)). Titles also bring together different urls or domains that have pointed to the resource over time. This means that each title can be linked to multiple urls. This notebook unpacks the title records to create an entry for each archived url.\n",
    "\n",
    "## Harvesting method\n",
    "\n",
    "There are two main processes used to harvest the data:\n",
    "\n",
    "- scraping Pandora's [complete list of titles](http://pandora.nla.gov.au/alpha/ALL) to save the link and name for each title\n",
    "- requesting a machine-readable version of the Title Entry Page (TEP) for each title and saving all the archived urls grouped within the title\n",
    "\n",
    "The title links have the form `/tep/[TEP number]` and lead to a human-readable Title Entry Page in Trove. However, by changing the url, you can get a JSON version of the TEP. For example:\n",
    "\n",
    "- [https://webarchive.nla.gov.au/tep/131444](https://webarchive.nla.gov.au/tep/131444) – goes to TEP web page\n",
    "- [https://webarchive.nla.gov.au/bamboo-service/tep/131444](https://webarchive.nla.gov.au/bamboo-service/tep/131444) – returns JSON version of TEP\n",
    "\n",
    "The JSON data includes a list of instances that point to individual snapshots (or Mementos) of the title. As far as I can tell, the TEPs only include snapshots captured through Pandora's selective archiving processes. Additional snapshots of a resource might have been captured by a domain crawl and included in the Australian Web Archive. A complete list of captures can be retrieved by using the url of the archived resource to [request a Timemap](https://glam-workbench.net/web-archives/get-all-versions/).\n",
    "\n",
    "The harvesting process attempts to extract all the archived urls from the `gatheredUrl` field in the instance data. However, it seems that when Pandora snapshots are migrated to the AWA, the `gatheredUrl` value is set to point to the snapshot, rather than the url of the original resource. The original url is embedded in the snapshot url, so the harvesting process extracts it using regular expressions.\n",
    "\n",
    "The urls extracted from each title record are de-duplicated, and each unique value is saved as a separate row in the resulting dataset. This means there can be multiple records for each title.\n",
    "\n",
    "## Dataset structure\n",
    "\n",
    "The dataset includes a row for each unique url from each title. The fields are:\n",
    "\n",
    "- `tep_id` – the TEP identifier in the form `/tep/[TEP NUMBER]`\n",
    "- `name` – name of the title\n",
    "- `gathered_url` – the url that was archived\n",
    "- `surt` – the surt (Sort-friendly URI Reordering Transform) is a version of the url that reverses the order of the domain components to put the top-level domain first, making it easier to group or sort resources by domain\n",
    "\n",
    "A pre-harvested version of this dataset is available from the [Pandora titles data](https://glam-workbench.net/trove-web-archives/pandora-titles-data/) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae9f72-18bb-42d9-9f58-0bfdd52a2a45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import requests_cache\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from surt import surt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "s = requests_cache.CachedSession(\"titles.db\")\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[502, 503, 504])\n",
    "s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "s.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc1306-f255-436e-bb39-c75ae36b7f23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def harvest_titles(output=\"titles_all.ndjson\", sample_only=False):\n",
    "    \"\"\"\n",
    "    Scrapes details of all titles from the Pandora website.\n",
    "    \"\"\"\n",
    "    Path(output).unlink(missing_ok=True)\n",
    "    page = 1\n",
    "    with tqdm() as pbar:\n",
    "        # Continue harvesting page by page until there's no results\n",
    "        while page:\n",
    "            # Request a page of title links\n",
    "            response = requests.get(f\"http://pandora.nla.gov.au/alpha/ALL/{page}\")\n",
    "            soup = BeautifulSoup(response.text, \"lxml\")\n",
    "            title_links = []\n",
    "            with Path(output).open(\"a\") as titles_file:\n",
    "                # Find all the item lists on the page and loop through them\n",
    "                for item_list in soup.find_all(\"div\", class_=\"itemlist\"):\n",
    "                    # Get all the tep links\n",
    "                    title_links = item_list.find_all(\"a\", href=re.compile(r\"/tep/\\d+\"))\n",
    "                    # Save the tep id and name\n",
    "                    for title_link in title_links:\n",
    "                        titles_file.write(\n",
    "                            json.dumps(\n",
    "                                {\n",
    "                                    \"tep_id\": title_link[\"href\"],\n",
    "                                    \"name\": title_link.string,\n",
    "                                }\n",
    "                            )\n",
    "                            + \"\\n\"\n",
    "                        )\n",
    "            pbar.update(1)\n",
    "            # If there's title links on this page, increment the page value and continue\n",
    "            if title_links and not sample_only:\n",
    "                page += 1\n",
    "            # If there's no title links then stop harvesting\n",
    "            else:\n",
    "                page = None\n",
    "            time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a17f4a-bef7-4536-b83f-bd00e0ea4a54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "harvest_titles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef2801-effb-4a92-b495-13f7973ae9a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Extract archived urls from TEP\n",
    "\n",
    "Now we'll request data for each TEP and extract the archived urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb39eb-8167-43ad-a993-290811913508",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_url(url):\n",
    "    \"\"\"\n",
    "    Get the harvested url from a Pandora snapshot link.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"^/?[A-Z0-9]*/?[A-Za-z0-9-]+/\", url)\n",
    "    if match:\n",
    "        url = url[match.end() :]\n",
    "    if not url.startswith(\"http\"):\n",
    "        url = f\"http://{url}\"\n",
    "    return url\n",
    "\n",
    "\n",
    "def add_title_urls(input=\"titles_all.ndjson\", output=\"title_urls.ndjson\"):\n",
    "    with Path(input).open(\"r\") as input_file:\n",
    "        with Path(output).open(\"w\") as output_file:\n",
    "            for line in tqdm(input_file):\n",
    "                tep_data = json.loads(line)\n",
    "                # Get TEP JSON\n",
    "                url = (\n",
    "                    f\"https://webarchive.nla.gov.au/bamboo-service{tep_data['tep_id']}\"\n",
    "                )\n",
    "                response = s.get(url)\n",
    "                # Some TEPs produce 500 errors -- seems they're no longer in the archive?\n",
    "                if response.ok:\n",
    "                    data = response.json()\n",
    "                    instance_urls = []\n",
    "                    # Title record includes multiple instances\n",
    "                    # An instance can be a different url, or a Pandora snapshot\n",
    "                    # We want to get all the distinct urls, so we'll trim the Pandora bits from urls and\n",
    "                    # use surts to merge http, https, www addresses\n",
    "                    surts = []\n",
    "                    for instance in data[\"instances\"]:\n",
    "                        # First we'll use the `gatheredUrl` field\n",
    "                        if gathered_url := instance.get(\"gatheredUrl\"):\n",
    "                            # Remove the Pandora part of the url (if there is one)\n",
    "                            gathered_url = clean_url(gathered_url)\n",
    "                            try:\n",
    "                                tep_surt = surt(gathered_url)\n",
    "                            # This is to handle a broken url\n",
    "                            except ValueError:\n",
    "                                gathered_url = gathered_url.replace(\n",
    "                                    \"http://https:\", \"http://\"\n",
    "                                )\n",
    "                                tep_surt = surt(gathered_url)\n",
    "                        # If there's no `gatheredUrl`, we'll use the `url`\n",
    "                        elif tep_url := instance.get(\"url\"):\n",
    "                            # Remove Pandora part of link\n",
    "                            gathered_url = re.search(\n",
    "                                r\"http://pandora.nla.gov.au/pan/\\w+/\\w+-\\w+/(.*)\",\n",
    "                                tep_url,\n",
    "                            ).group(1)\n",
    "                            if not gathered_url.startswith(\"http\"):\n",
    "                                gathered_url = f\"http://{gathered_url}\"\n",
    "                            tep_surt = surt(gathered_url)\n",
    "                        else:\n",
    "                            tep_surt = None\n",
    "                        # Add url to list if we don't already have it (check surts)\n",
    "                        if tep_surt and tep_surt not in surts:\n",
    "                            instance_urls.append(gathered_url)\n",
    "                            surts.append(tep_surt)\n",
    "                    # Save each url\n",
    "                    for instance_url in sorted(set(instance_urls)):\n",
    "                        tep_data[\"gathered_url\"] = instance_url\n",
    "                        tep_data[\"surt\"] = surt(instance_url)\n",
    "                        output_file.write(json.dumps(tep_data) + \"\\n\")\n",
    "                    if not response.from_cache:\n",
    "                        time.sleep(0.5)\n",
    "                else:\n",
    "                    output_file.write(json.dumps(tep_data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b4a3b-8bfd-41d9-a044-64f42eb04c3e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "add_title_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a934fe-14e9-43cb-b270-e321d647db51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "dft = pd.read_json(\"title_urls.ndjson\", lines=True)\n",
    "dft.to_csv(\"pandora-titles.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cbc3e5-c8e9-427c-937e-9f1fff829c39",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IGNORE THIS CELL -- TESTING ONLY\n",
    "if os.getenv(\"GW_STATUS\") == \"dev\":\n",
    "    harvest_titles(output=\"test.ndjson\", sample_only=True)\n",
    "    add_title_urls(input=\"test.ndjson\", output=\"test_urls.ndjson\")\n",
    "    Path(\"test.ndjson\").unlink()\n",
    "    Path(\"test_urls.ndjson\").unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e4e155-3ec9-446b-ac11-d95f476cc23f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "----\n",
    "\n",
    "Created by [Tim Sherratt](https://timsherratt.au/) for the [GLAM Workbench](https://glam-workbench.net/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rocrate": {
   "action": [
    {
     "description": "This dataset contains a complete list of Pandora's archived web resource titles.",
     "isPartOf": "https://github.com/GLAM-Workbench/trove-web-archives-titles",
     "mainEntityOfPage": "https://glam-workbench.net/trove-web-archives/pandora-titles-data",
     "result": [
      {
       "license": "https://creativecommons.org/publicdomain/zero/1.0/",
       "url": "https://github.com/GLAM-Workbench/trove-web-archives-titles/raw/main/pandora-titles.csv"
      }
     ]
    }
   ],
   "author": [
    {
     "mainEntityOfPage": "https://timsherratt.au",
     "name": "Sherratt, Tim",
     "orcid": "https://orcid.org/0000-0001-7956-4498"
    }
   ],
   "description": "This notebook harvests a complete collection of archived web page titles from [Pandora](http://pandora.nla.gov.au/), the National Library of Australia's selective web archive.\n\nPandora has been selecting web sites and online resources for preservation since 1996. It has assembled a collection of more than 80,000 titles, organised into subjects and collections. The archived websites are now part of the Australian Web Archive (AWA), which combines the selected titles with broader domain harvests, and is searchable through Trove. However, Pandora's curated collections offer a useful entry point for researchers trying to find web sites relating to particular topics or events.",
   "mainEntityOfPage": "https://glam-workbench.net/trove-web-archives/harvest-pandora-titles/",
   "name": "Harvest the full collection of Pandora titles",
   "position": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
