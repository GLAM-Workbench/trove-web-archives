{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5241964-ff09-4c34-b164-32befd8ac430",
   "metadata": {},
   "source": [
    "# Create archived url datasets from Pandora's collections and subjects\n",
    "\n",
    "This notebook helps you create a dataset of archived urls using Pandora's subject and collection groupings.\n",
    "\n",
    "The Australian Web Archive makes billions of archived web pages searchable through Trove. But how would you go about constructing a search that would find websites relating to election campaigns? Fortunately you don't have to, as Pandora provides a collection of archived web resources organised by subject and collection. By using harvests of Pandora's subject hierarchy and a complete list of archived titles, this notebook makes it easy for you to create custom datasets relating to a specific topic or event.\n",
    "\n",
    "This notebook uses pre-harvested datasets containing information about Pandora's subjects, collections and titles. New titles are added to Pandora frequently, so you might want to create your own updated versions using these notebooks:\n",
    "\n",
    "- [Harvest Pandora subjects and collections](harvest-pandora-subject-collections.ipynb)\n",
    "- [Harvest the full collection of Pandora titles](harvest-pandora-titles.ipynb)\n",
    "\n",
    "## Using this notebook\n",
    "\n",
    "The simplest way to get started is to browse the subject and collection groupings in [Pandora](http://pandora.nla.gov.au/). Once you've found a subject or collection of interest, just copy its identifier, either `/subject/[subject number]` or `/col/[collection number]`. You also need to decide if you want *every* title under that subject or collection, including those associated with its children, or if you only want the titles directly linked to your selected grouping.\n",
    "\n",
    "Then you can run either `create_subject_dataset([your subject id])` or `create_collection_dataset([your collection id])`.\n",
    "\n",
    "## Datasets\n",
    "\n",
    "This notebook creates a CSV formatted dataset containing the following fields:\n",
    "\n",
    "- `tep_id` – the Title Entry Page (TEP) identifier in the form `/tep/[TEP NUMBER]`\n",
    "- `name` – name of the title\n",
    "- `gathered_url` – the url that was archived\n",
    "- `surt` – the surt (Sort-friendly URI Reordering Transform) is a version of the url that reverses the order of the domain components to put the top-level domain first, making it easier to group or sort resources by domain\n",
    "\n",
    "Note that Pandora's title records can bring together different urls and domains that have pointed to a resource over time. This means that there can be multiple urls associated with each TEP. See [Harvest the full collection of Pandora titles](harvest-pandora-titles.ipynb) for more information.\n",
    "\n",
    "The dataset also includes an RO-Crate metadata file describing the dataset's contents and context.\n",
    "\n",
    "## What can you do with a collection of archived urls?\n",
    "\n",
    "For more information about the Pandora title, use the `tep_id` to construct a url to a human-readable version in Trove, or a machine-readable JSON version:\n",
    "\n",
    "- [https://webarchive.nla.gov.au/tep/131444](https://webarchive.nla.gov.au/tep/131444) – goes to TEP web page\n",
    "- [https://webarchive.nla.gov.au/bamboo-service/tep/131444](https://webarchive.nla.gov.au/bamboo-service/tep/131444) – returns JSON version of TEP\n",
    "\n",
    "Once you have an archived url you can make use of the tools in the [Web Archives](https://glam-workbench.net/web-archives/) section of the GLAM Workbench to gather more data for analysis. For example:\n",
    "\n",
    "- [Find all the archived versions of a web page using Timemaps](https://glam-workbench.net/web-archives/get-all-versions/)\n",
    "- [Display changes in the text of an archived web page over time](https://glam-workbench.net/web-archives/display-changes-in-text/)\n",
    "- [Harvesting collections of text from archived web pages](https://glam-workbench.net/web-archives/harvesting-text/)\n",
    "- [Using screenshots to visualise change in a page over time](https://glam-workbench.net/web-archives/create-screenshots-over-time/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "9362f044-66c3-44b4-b4b4-8566603bb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import mimetypes\n",
    "\n",
    "import ipynbname\n",
    "import nbformat\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from rocrate.rocrate import ContextEntity, ROCrate\n",
    "from slugify import slugify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "1ab9af6c-01d7-459b-8595-31325aeb3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = pd.read_json(\n",
    "    \"https://github.com/GLAM-Workbench/trove-web-archives-collections/raw/main/pandora-collections.ndjson\",\n",
    "    lines=True,\n",
    ")\n",
    "dfs = pd.read_json(\n",
    "    \"https://github.com/GLAM-Workbench/trove-web-archives-collections/raw/main/pandora-subjects.ndjson\",\n",
    "    lines=True,\n",
    ")\n",
    "dft = pd.read_csv(\n",
    "    \"https://github.com/GLAM-Workbench/trove-web-archives-titles/raw/main/pandora-titles.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "def create_rocrate(subject, file_path, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Create an RO-Crate metadata file describing the downloaded dataset.\n",
    "    \"\"\"\n",
    "    crate = ROCrate()\n",
    "    crate.add_file(file_path)\n",
    "    nb_path = ipynbname.path()\n",
    "    nb = nbformat.read(nb_path, nbformat.NO_CONVERT)\n",
    "    metadata = nb.metadata.rocrate\n",
    "    nb_url = metadata.get(\"url\", \"\")\n",
    "    nb_properties = {\n",
    "        \"@type\": [\"File\", \"SoftwareSourceCode\"],\n",
    "        \"name\": metadata.get(\"name\", \"\"),\n",
    "        \"description\": metadata.get(\"description\", \"\"),\n",
    "        \"encodingFormat\": \"application/x-ipynb+json\",\n",
    "        \"codeRepository\": metadata.get(\"codeRepository\", \"\"),\n",
    "        \"url\": nb_url,\n",
    "    }\n",
    "    crate.add(ContextEntity(crate, nb_url, properties=nb_properties))\n",
    "    action_id = f\"{nb_path.stem}_run\"\n",
    "    action_properties = {\n",
    "        \"@type\": \"CreateAction\",\n",
    "        \"instrument\": {\"@id\": nb_url},\n",
    "        \"actionStatus\": {\"@id\": \"http://schema.org/CompletedActionStatus\"},\n",
    "        \"name\": f\"Run of notebook: {nb_path.name}\",\n",
    "        \"result\": {\"@id\": f\"{file_path.name}/\"},\n",
    "        \"object\": [{\"@id\": o[\"url\"]} for o in metadata[\"action\"][0][\"object\"]],\n",
    "        \"query\": f\"{subject['id']} ({subject['name']})\",\n",
    "        \"startDate\": start_date,\n",
    "        \"endDate\": end_date,\n",
    "    }\n",
    "    encoding = mimetypes.guess_type(file_path)[0]\n",
    "    stats = file_path.stat()\n",
    "    size = stats.st_size\n",
    "    date = datetime.fromtimestamp(stats.st_mtime).strftime(\"%Y-%m-%d\")\n",
    "    rows = 0\n",
    "    with file_path.open(\"r\") as df:\n",
    "        for line in df:\n",
    "            rows += 1\n",
    "    crate.update_jsonld(\n",
    "        {\n",
    "            \"@id\": file_path.name,\n",
    "            \"dateModified\": date,\n",
    "            \"contentSize\": size,\n",
    "            \"size\": rows,\n",
    "            \"encodingFormat\": encoding,\n",
    "        }\n",
    "    )\n",
    "    crate.add(ContextEntity(crate, action_id, properties=action_properties))\n",
    "    crate.write(file_path.parent)\n",
    "    crate.write_zip(file_path.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d3ded-e4f9-4dfd-88b0-9c62a319f26f",
   "metadata": {},
   "source": [
    "## Get title urls from a Pandora subject group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "cb8497ee-fae1-4252-bdb4-5fe1ab6fb12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_ids_in_collection(coll_id, include_subcollections=True):\n",
    "    title_ids = []\n",
    "    coll = dfc.loc[dfc[\"id\"] == coll_id].iloc[0]\n",
    "    title_ids += coll[\"titles\"]\n",
    "    if include_subcollections:\n",
    "        for scoll_id in coll[\"subcollections\"]:\n",
    "            scoll = dfc.loc[dfc[\"id\"] == scoll_id].iloc[0]\n",
    "            title_ids += scoll[\"titles\"]\n",
    "    return title_ids\n",
    "\n",
    "\n",
    "def get_urls_by_subject(subject, include_subcategories=False, include_collections=False):\n",
    "    title_ids = []\n",
    "    title_ids += subject[\"titles\"]\n",
    "    if include_subcategories:\n",
    "        for subc_id in subject[\"subcategories\"]:\n",
    "            subc = dfs.loc[dfs[\"id\"] == subc_id].iloc[0]\n",
    "            title_ids += subc[\"titles\"]\n",
    "            if include_collections:\n",
    "                for coll_id in subc[\"collections\"]:\n",
    "                    title_ids += get_title_ids_in_collection(coll_id)\n",
    "    if include_collections:\n",
    "        for coll_id in subject[\"collections\"]:\n",
    "            title_ids += get_title_ids_in_collection(coll_id)\n",
    "    titles = dft.loc[dft[\"tep_id\"].isin(title_ids)]\n",
    "    return titles\n",
    "\n",
    "\n",
    "def create_subject_dataset(id, include_subcategories=False, include_collections=False):\n",
    "    start_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    subject = dfs.loc[dfs[\"id\"] == id].iloc[0]\n",
    "    \n",
    "    df = get_urls_by_subject(\n",
    "        subject,\n",
    "        include_subcategories=include_subcategories,\n",
    "        include_collections=include_collections,\n",
    "    )\n",
    "    \n",
    "    end_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    subject_slug = slugify(f\"pandora-{id}-{subject['name']}\")\n",
    "    output_path = Path(\"datasets\", subject_slug)\n",
    "    output_path.mkdir(exist_ok=True, parents=True)\n",
    "    output_file = Path(output_path, f\"pandora-{subject_slug}.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    create_rocrate(subject, output_file, start_date, end_date)\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"Download dataset: <a href='datasets/{subject_slug}.zip', download>datasets/{subject_slug}.zip</a>\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "a9895f20-1891-4c5e-8bfe-bb3ef54f023f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Download dataset: <a href='datasets/subject-3-business-economy.zip', download>datasets/subject-3-business-economy.zip</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_subject_dataset(\n",
    "    \"/subject/3\", include_subcategories=True, include_collections=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e5aafe-6884-457f-a249-fc3a0f40f42f",
   "metadata": {},
   "source": [
    "## Get title urls from a Pandora collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a1f8b140-1453-4b1f-ba7f-6bdb3e77b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titles_by_collection(coll, include_subcollections=True):\n",
    "    title_ids = get_title_ids_in_collection(\n",
    "        coll[\"id\"], include_subcollections=include_subcollections\n",
    "    )\n",
    "    titles = dft.loc[dft[\"tep_id\"].isin(title_ids)]\n",
    "    return titles\n",
    "\n",
    "\n",
    "def create_collection_dataset(id, include_subcollections=False):\n",
    "    start_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    coll = dfc.loc[dfc[\"id\"] == id].iloc[0]\n",
    "    df = get_titles_by_collection(\n",
    "        coll,\n",
    "        include_subcollections=include_subcollections,\n",
    "    )\n",
    "    end_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    coll_slug = slugify(f\"pandora-{id}-{coll['name']}\")\n",
    "    \n",
    "    output_path = Path(\"datasets\", coll_slug)\n",
    "    output_path.mkdir(exist_ok=True, parents=True)\n",
    "    output_file = Path(output_path, f\"pandora-{coll_slug}.csv\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    create_rocrate(coll, output_file, start_date, end_date)\n",
    "    display(\n",
    "        HTML(\n",
    "            f\"Download dataset: <a href='datasets/{coll_slug}.zip', download>datasets/{coll_slug}.zip</a>\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "f9dff1c6-4305-4d87-976e-a11f72a914e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Download dataset: <a href='datasets/pandora-col-21326-museums.zip', download>datasets/pandora-col-21326-museums.zip</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_collection_dataset(\"/col/21326\", include_subcollections=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ecfc37-359a-4021-b157-4b9fbe1f0dea",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Created by [Tim Sherratt](https://timsherratt.au/) for the [GLAM Workbench](https://glam-workbench.net/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rocrate": {
   "action": [
    {
     "object": [
      {
       "url": "https://github.com/GLAM-Workbench/trove-web-archives-titles/raw/main/pandora-titles.csv"
      },
      {
       "url": "https://github.com/GLAM-Workbench/trove-web-archives-collections/raw/main/pandora-subjects.ndjson"
      },
      {
       "url": "https://github.com/GLAM-Workbench/trove-web-archives-collections/raw/main/pandora-collections.ndjson"
      }
     ]
    }
   ],
   "author": [
    {
     "mainEntityOfPage": "https://timsherratt.au",
     "name": "Sherratt, Tim",
     "orcid": "https://orcid.org/0000-0001-7956-4498"
    }
   ],
   "description": "This notebook helps you create a dataset of archived urls using Pandora's subject and collection groupings.\n\nThe Australian Web Archive makes billions of archived web pages searchable through Trove. But how would you go about constructing a search that would find websites relating to election campaigns? Fortunately you don't have to, as Pandora provides a collection of archived web resources organised by subject and collection. By using harvests of Pandora's subject hierarchy and a complete list of archived titles, this notebook makes it easy for you to create custom datasets relating to a specific topic or event.",
   "mainEntityOfPage": "https://glam-workbench.net/trove-web-archives/create-datasets/",
   "name": "Create title datasets from collections and subjects",
   "url": "https://github.com/GLAM-Workbench/trove-web-archives/raw/master/create-datasets.ipynb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
